name: Run Node.js Scraper

on:
  workflow_dispatch:  # Trigger the workflow manually via GitHub UI

jobs:
  run-scraper:
    runs-on: windows-latest  # This will run the job on a Windows server

    steps:
      # Step 1: Checkout the repository code
      - name: Checkout repository
        uses: actions/checkout@v3  # Check out the repo to access the scraper file

      # Step 2: Set up Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'  # You can specify the version of Node.js you're using

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          npm install  # Installs dependencies from package.json

      # Step 4: Run scraper
      - name: Run scraper
        run: |
          node scraper.js  # This will run your scraper.js file

      # Step 5: Commit and push the scraped data (if applicable)
      - name: Commit and push scraped data
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add scrapedData.json  # Add the new data file (if it exists)
          git commit -m "Update scraped data"
          git push  # Push the changes back to the repo
